---
title: "The BET model"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The BET model}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
bibliography: "references.bib"
link-citations: yes
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

# Introduction

The `sbt` software is an R package [@R2024] that contains the CCSBT operating 
model (OM) coded using RTMB [@Kristensen2016, @Kristensen2024]. This page 
provides examples using the `sbt` model.

# Load inputs

The `sbt` RTMB model is loaded along with several R functions using 
`library(sbt)`. The `kableExtra` package is used for generating tables of 
inputs. The `tidyverse` package is used for data manipulation and plotting. The 
code `theme_set(theme_bw())` alters the plot aesthetics.

```{r load-pkg, echo=TRUE, message=FALSE}
# remotes::install_github("janoleko/RTMBdist")
# remotes::install_github("andrjohns/StanEstimators")
# remotes::install_github("noaa-afsc/SparseNUTS")
library(kableExtra)
library(tidyverse)
library(reshape2)
# library(bet)
devtools::load_all()

theme_set(theme_bw())
```

```{r get-biology, echo=TRUE, message=FALSE}
# Load MFCL files to extract biology
library(FLR4MFCL)
library(data.table)
library(magrittr)

proj_dir <- this.path::this.proj()
dir_model <- file.path(proj_dir, "..", "..", "..", "model-files")
dir_base_mfcl <- file.path(dir_model, "mfcl", "v11")

# Read MFCL files
base_par <- read.MFCLPar(file.path(dir_base_mfcl, "10.par"), first.yr = 1952)
base_rep <- read.MFCLRep(file.path(dir_base_mfcl, "plot-10.par.rep"))
base_ini <- read.MFCLIni(file.path(dir_base_mfcl, "bet.ini"), nseasons = 4)

# Quarterly age classes matching MFCL/SS3: ages 1-40 represent 0.25-10.0 real years
ages <- 1:40

# Growth parameters from MFCL
# Extract mean length-at-age and SD from MFCL report
tmp_laa_dt <- as.data.table(mean_laa(base_rep))
tmp_sdlaa_dt <- as.data.table(sd_laa(base_rep))

# Mean length-at-age by quarter (40 quarterly ages)
mean_length_at_age <- tmp_laa_dt$value

# SD of length-at-age by quarter
sd_length_at_age <- tmp_sdlaa_dt$value

# Plot mean length-at-age
plot_data <- data.frame(
  age = ages,
  real_age = ages / 4,  # convert to real years
  length_cm = mean_length_at_age,
  sd = sd_length_at_age
)

ggplot(data = plot_data, aes(x = real_age, y = length_cm)) +
  geom_ribbon(aes(ymin = length_cm - sd, ymax = length_cm + sd), alpha = 0.2) +
  geom_line() +
  geom_point() +
  labs(x = "Age (years)", y = "Mean length (cm)", 
       title = "Von Bertalanffy Growth Curve from MFCL")

# Maturity-at-length from MFCL
# Define length bins for maturity conversion: 10 to 200 cm by 2 cm
len_lower <- seq(10, 198, by = 2)
len_upper <- seq(12, 200, by = 2)
n_len <- length(len_lower)
len_mid <- (len_lower + len_upper) / 2

# Extract maturity-at-length from MFCL and interpolate to model length bins
mfcl_bin_lower <- seq(2, 198, by = 2)
mfcl_bin_mid <- mfcl_bin_lower + 1
mat_at_length_mfcl <- as.vector(mat_at_length(base_par))

# Interpolate maturity to our length bins
maturity_at_length <- approx(
  x = mfcl_bin_mid,
  y = mat_at_length_mfcl,
  xout = len_mid,
  method = "linear",
  rule = 2
)$y

# Plot maturity-at-length
ggplot(data = data.frame(length = len_mid, maturity = maturity_at_length), 
       aes(x = length, y = maturity)) +
  geom_line() +
  geom_point() +
  labs(x = "Length (cm)", y = "Maturity", 
       title = "Maturity-at-Length from MFCL")

# Natural mortality from MFCL
M_at_age <- as.vector(m_at_age(base_rep))

# Plot M-at-age
ggplot(data = data.frame(age = ages, real_age = ages / 4, M = M_at_age), 
       aes(x = real_age, y = M)) +
  geom_line() +
  geom_point() +
  labs(x = "Age (years)", y = "M (quarterly rate)", 
       title = "Natural Mortality-at-Age from MFCL")
```
The data list is defined below and then the `get_data` function is used to set 
up some additional inputs that are required before the data list can be passed 
to `MakeADFun`.

```{r get-data, echo=TRUE, message=FALSE}
df_catch <- read_csv("catch-data.csv")
df_cpue <- read_csv("cpue-data.csv")

table(df_catch$year)
table(df_catch$fishery, df_catch$units)

# Quarterly age classes and time structure
data <- list(
  age_a = ages,
  n_age = length(ages),
  n_season = 1,  # Each time step is one quarter, not seasons within years
  n_fishery = 15,
  len_lower = len_lower,
  len_upper = len_upper,
  n_len = n_len
)

# Use ts column as the year index (quarterly time steps)
data$first_yr <- min(df_catch$ts)
data$last_yr <- max(df_catch$ts)
data$years <- data$first_yr:data$last_yr
data$n_year <- length(data$years)
data$first_yr_catch <- data$first_yr
data$catch_units_f <- c(rep(2, 7), rep(1, 7), 2)
data$cpue_switch <- 1
data$cpue_data <- df_cpue

# Convert maturity-at-length to maturity-at-age using get_pla()
# get_pla() returns an L x A matrix (age-length key)
pla <- get_pla(len_lower, len_upper, mu_a = mean_length_at_age, sd_a = sd_length_at_age)

# mat_a[a] = sum_over_L[ mat(L) * P(L|a) ]
# pla is L x A, maturity_at_length is length L vector
# Result is an A-length vector
maturity_a <- as.vector(t(pla) %*% maturity_at_length)

# Plot maturity-at-age
plot_data_mat <- data.frame(
  age = ages,
  real_age = ages / 4,
  maturity = maturity_a
)
ggplot(data = plot_data_mat, aes(x = real_age, y = maturity)) +
  geom_line() +
  geom_point() +
  labs(x = "Age (years)", y = "Maturity", 
       title = "Maturity-at-Age from MFCL (converted from maturity-at-length)")

data$maturity_a <- maturity_a

# Store M-at-age as data (not a parameter)
data$M_a <- M_at_age

# Catch array: (n_year, 1, n_fishery) - map using ts directly
catch_obs_ysf <- array(0, 
                       dim = c(data$n_year, data$n_season, data$n_fishery), 
                       dimnames = list(year = data$years, season = 1, fishery = 1:data$n_fishery))
for (i in 1:nrow(df_catch)) {
  row <- df_catch[i, ]
  y_idx <- which(data$years == row$ts)
  catch_obs_ysf[y_idx, 1, row$fishery] <- row$value
}
data$catch_obs_ysf <- catch_obs_ysf

# Weight-at-age: Use get_weight_at_age() with MFCL growth parameters
# First need to create a year x season x age array for length_mu_ysa
# For simplicity, we'll use the same length-at-age for all years (MFCL quarterly averages)
length_mu_ysa <- array(dim = c(data$n_year, 1, data$n_age))
for (y in 1:data$n_year) {
  length_mu_ysa[y, 1, ] <- mean_length_at_age
}

# Note: get_weight_at_age() is currently designed for 6 fisheries (SBT)
# For now, we'll use a simplified approach with a single L-W relationship
# This will need to be updated later to handle 15 BET fisheries properly

# Use MFCL length-weight parameters from ini file
lw_a <- lw_params(base_ini)[1]
lw_b <- lw_params(base_ini)[2]

# Calculate weight-at-age for all fisheries (simplified - same L-W for all)
data$weight_fya <- array(dim = c(data$n_fishery, data$n_year, data$n_age))
for (f in 1:data$n_fishery) {
  for (y in 1:data$n_year) {
    # Integrate L-W over length-at-age distribution
    for (a in 1:data$n_age) {
      # Simple approach: use mean length
      mu_len <- mean_length_at_age[a]
      sd_len <- sd_length_at_age[a]
      
      # Integrate over Â±4 SD
      len_vals <- seq(max(1, mu_len - 4 * sd_len), mu_len + 4 * sd_len, length.out = 100)
      dens_vals <- dnorm(len_vals, mean = mu_len, sd = sd_len)
      dens_vals <- dens_vals / sum(dens_vals)  # normalize
      wt_vals <- lw_a * len_vals^lw_b
      data$weight_fya[f, y, a] <- sum(wt_vals * dens_vals) / 1000  # kg
    }
  }
}

# Plot weight-at-age for first fishery
plot_data_wt <- data.frame(
  age = ages,
  real_age = ages / 4,
  weight_kg = data$weight_fya[1, 1, ]
)
ggplot(data = plot_data_wt, aes(x = real_age, y = weight_kg)) +
  geom_line() +
  geom_point() +
  labs(x = "Age (years)", y = "Weight (kg)", 
       title = "Weight-at-Age from MFCL (Fishery 1)")

data$weight_fya[1, 1, ]
```

# Model setup

Define the parameter `list`:

```{r get-pars, echo=TRUE, message=FALSE}
# parameters <- get_parameters(data = data)
# names(parameters)
# Note: log_M removed - M-at-age now read from data
# Note: rdev_y length now matches n_year (268 quarterly time steps)
parameters <- list(
  log_B0 = 13,
  log_h = log(0.8),
  log_sigma_r = log(0.6),
  log_cpue_q = log(1),
  cpue_creep = 0,
  log_cpue_tau = log(0.2),
  log_cpue_omega = log(1),
  rdev_y = rnorm(data$n_year, 0, 0.1)
  # rdev_y = rep(0, data$n_year)
)
```

There is a lot of flexibility in specifying priors now:

```{r get-priors, echo=TRUE, message=FALSE}
data$priors <- get_priors(parameters = parameters)
evaluate_priors(parameters = parameters, priors = data$priors)
```

Use RTMB's `map` option to turn parameters on/off:

```{r get-map, echo=TRUE, message=FALSE}
# map <- get_map(parameters = parameters)
# Note: log_M removed - M-at-age now read from data
map <- list(
  # log_B0 = factor(NA),
  log_h = factor(NA),
  log_sigma_r = factor(NA),
  # log_cpue_q = factor(NA),
  cpue_creep = factor(NA),
  log_cpue_tau = factor(NA),
  log_cpue_omega = factor(NA)
)
```

Using the `data`, the `parameters`, the parameter `map`, and the model 
(`bet_model`), the AD object is created using TMBs `MakeADFun` function:

```{r make-adfun, echo=TRUE, message=FALSE}
obj <- MakeADFun(func = cmb(bet_model, data), parameters = parameters, map = map)
obj$fn()
obj$gr()

obj$simulate()$cpue_log_obs

plot_catch(data = data, object = obj)
plot_cpue(data = data, object = obj)
plot_biomass_spawning(data_list = list(data), object_list = list(obj))
```

List of parameters that are on:

```{r est-pars, echo=TRUE, message=FALSE}
unique(names(obj$par))
```

The objective function value given the initial parameter values:

```{r check-obj-fun, echo=TRUE, message=FALSE}
obj$fn(obj$env$last.par.best)
obj$gr(obj$env$last.par.best)
```

Load the default parameter bounds:

```{r get-par-bounds, echo=TRUE, message=FALSE}
bnd <- get_bounds(obj, parameters = parameters)
```

# Optimisation

Optimise using the `nlminb` function:

```{r run-nlminb, echo=TRUE, results="hide"}
control <- list(eval.max = 10000, iter.max = 10000)
opt <- nlminb(start = obj$par, objective = obj$fn,
              lower = bnd$lower, upper = bnd$upper, control = control)
opt <- nlminb(start = opt$par, objective = obj$fn,
              lower = bnd$lower, upper = bnd$upper, control = control)
# opt <- nlminb(start = obj$par, objective = obj$fn, gradient = obj$gr, hessian = obj$he,
#               lower = bnd$lower, upper = bnd$upper, control = control)
# opt <- nlminb(start = opt$par, objective = obj$fn, gradient = obj$gr, hessian = obj$he,
#               lower = bnd$lower, upper = bnd$upper, control = control)
# save(opt, file = "opt.rda")
# load("opt.rda")
# opt <- nlminb(start = opt$par, objective = obj$fn, gradient = obj$gr, hessian = obj$he,
#               lower = bnd$lower, upper = bnd$upper, control = control)
```

Check that all parameters are estimable using the `check_estimability` function.
This function was taken from the `TMBhelper` package and added to the `sbt` 
package because the `TMBhelper` package is not set up as a proper package (it 
does not install properly on the GitHub servers).

```{r check-estimability, echo=TRUE, message=FALSE}
check_estimability(obj = obj)
```

Calculate standard deviations of all model parameters, including non linear 
functions of random effects and parameters specified through the `ADREPORT()` 
macro from the user template:

```{r run-report, include=FALSE}
Report <- sdreport(obj)
```

# Simulation

Simulation can be done for any data set in the model that is passed through the
`RTMB` function `OBS`. For example, the CPUE series is set up using:

```
cpue_log_obs <- log(cpue_obs)
cpue_log_obs <- OBS(cpue_log_obs)
lp <- -dnorm(x = cpue_log_obs, mean = cpue_log_pred, sd = cpue_sig, log = TRUE)
```

This allows a call to `obj$simulate()$cpue_log_obs`. For example:

```{r sim-1, echo=TRUE, message=FALSE}
# obj$simulate()$cpue_log_obs
# obj$simulate()$troll_log_obs
# obj$simulate()$aerial_log_obs
# obj$simulate()$gt_nrec
# obj$simulate()$hsp_nK
# obj$simulate()$pop_nP
plot(log(data$cpue_obs), col = 2)
for (i in 1:10) lines(obj$simulate()$cpue_log_obs)
```

Data sets for which simulation is available include:

* cpue_log_obs

But not:

* lf_obs
* cpue_lfs

Simulation is also required for calculating OSA residuals and to use the `RTMB` 
function `checkConsistency`. Unfortunately, the `checkConsistency` does not work 
yet because  not all data types are defined using densities that have simulation 
support within the model (i.e., the AFs and LFs).

```{r check-consistency, echo=TRUE}
# chk <- checkConsistency(obj = obj, hessian = TRUE, estimate = TRUE, n = 100, observation.name	= "cpue_log_obs")
# chk
# s <- summary(chk)
# s
# s$marginal$p.value
```

# Plot outputs

## Model fits

Model fit to CPUE (Figure~\ref(fig:plot-cpue)) and the aerial surveys (Figure~\ref(fig:plot-aerial)).

```{r plot-cpue, echo=TRUE, message=FALSE, fig.cap="Model fits to CPUE."}
plot_cpue(data = data, object = obj, nsim = 10)
```

```{r plot-LL1, echo=TRUE, message=FALSE, fig.height=10, fig.cap="Model fits to LL1 length frequencies."}
plot_lf(data = data, object = obj, fishery = "LL1")
```

```{r plot-LL2, echo=TRUE, message=FALSE, fig.height=10, fig.cap="Model fits to LL2 length frequencies."}
plot_lf(data = data, object = obj, fishery = "LL2")
```

```{r plot-LL3, echo=TRUE, message=FALSE, fig.height=10, fig.cap="Model fits to LL3 length frequencies."}
plot_lf(data = data, object = obj, fishery = "LL3")
```

```{r plot-LL4, echo=TRUE, message=FALSE, fig.height=10, fig.cap="Model fits to LL4 length frequencies."}
plot_lf(data = data, object = obj, fishery = "LL4")
```

```{r plot-catch, echo=TRUE, message=FALSE}
plot_catch(data = data, object = obj)
```

```{r plot-catch-resid, echo=TRUE, message=FALSE}
plot_catch(data = data, object = obj, plot_resid = TRUE)
```

## One step ahead (OSA) residuals

One step ahead (OSA) residuals are a replacement for Pearson residuals 
(Figure~\ref(fig:osa1)).

```{r osa1, echo=TRUE, message=FALSE, fig.cap="OSA residuals."}
osa_cpue <- oneStepPredict(obj = obj, observation.name = "cpue_log_obs", 
                           method = "oneStepGeneric", trace = FALSE)
qqnorm(osa_cpue$res); abline(0, 1)
plot(osa_cpue$res); abline(-2, 0); abline(0, 0); abline(2, 0)
# osa <- oneStepPredict(obj = obj, method = "fullGaussian", discrete = FALSE, trace = FALSE)
# osa_troll <- oneStepPredict(obj = obj, observation.name = "troll_log_obs", method = "oneStepGeneric", trace = FALSE)
# qqnorm(osa_troll$res); abline(0, 1)
# plot(osa_troll$res); abline(0, 0)
# osa_aerial <- oneStepPredict(obj = obj, observation.name = "aerial_log_obs", method = "oneStepGeneric", trace = FALSE)
# qqnorm(osa$res); abline(0, 1)
# osa_gt <- oneStepPredict(obj = obj, observation.name = "gt_nrec", method = "oneStepGeneric", discrete = TRUE, trace = FALSE)
# qqnorm(osa_gt$res); abline(0, 1)
# plot(osa_gt$res); abline(-2, 0); abline(0, 0); abline(2, 0)
# osa_hsp <- oneStepPredict(obj = obj, observation.name = "hsp_nK", method = "oneStepGeneric", discrete = TRUE, trace = FALSE)
# qqnorm(osa_hsp$res); abline(0, 1)
# plot(osa_hsp$res); abline(0, 0)
# osa_pop <- oneStepPredict(obj = obj, observation.name = "pop_nP", method = "oneStepGeneric", discrete = TRUE, trace = FALSE)
# qqnorm(osa_pop$res); abline(0, 1)
# plot(osa_pop$res); abline(0, 0)
```

## Derived quantities

Recruitment deviates and recruitment (Figure~\ref(fig:plot-rec-dev), Figure~\ref(fig:plot-rec)).

```{r plot-rec-dev, echo=TRUE, message=FALSE}
plot_rec_devs(data = data, object = obj)
```

```{r plot-rec, echo=TRUE, message=FALSE}
plot_recruitment(data = data, object = obj)
```

```{r plot-M, echo=TRUE, message=FALSE}
plot_natural_mortality(data = data, object = obj)
```

```{r plot-init-n, echo=TRUE, message=FALSE}
plot_initial_numbers(data = data, object = obj)
```

```{r plot-hrate, echo=TRUE, message=FALSE}
plot_hrate(data = data, object = obj, years = 1990:2010)
```

```{r plot-sbio, echo=TRUE, message=FALSE, fig.cap="Spawning biomass by year."}
plot_biomass_spawning(data_list = list(data), object_list = list(obj))
```

# Likelihood profiles

Likelihood profiles can be done for any model parameter using the function 
`sbtprofile`. The `ytol` argument defines the range of likelihood values to 
explore. A profile can be run using either using `name` or `lincomb` arguments, 
where the latter can be used if there are multiple parameters with the same name 
(e.g., `par_log_sel_1`).

```{r run-like-prof, echo=TRUE, results="hide"}
# ytol <- 9
# prof_B0 <- sbtprofile(obj = obj, name = "par_log_B0", ytol = ytol)
# prof_m4 <- sbtprofile(obj = obj, name = "par_log_m4", ytol = ytol)
# prof_m30 <- sbtprofile(obj = obj, name = "par_log_m30", ytol = ytol)
# lincomb <- numeric(length(obj$par)); lincomb[6] <- 1
# prof_sel1 <- sbtprofile(obj = obj, lincomb = lincomb, ytol = ytol)
# save(prof_B0, prof_m4, prof_m30, prof_sel1, file = "profiles.rda")
load("profiles.rda")
```

Note that the profile for B0 did not work very well, likelihood for LFs was zero 
when B0 was too low. Need to look into this.

```{r fig-prof1, echo=TRUE, results="hide", fig.cap="Likelihood profile for B0."}
head(prof_B0)
obj$env$last.par.best[names(obj$par) == "par_log_B0"]
plot_profile(x = prof_B0 %>% filter(is.finite(value)), xlab = "B0")
```

```{r fig-prof2, echo=TRUE, results="hide", fig.cap="Likelihood profile for M4."}
plot_profile(x = prof_m4, xlab = "M4")
```

```{r fig-prof3, echo=TRUE, results="hide", fig.cap="Likelihood profile for M30."}
plot_profile(x = prof_m30, xlab = "M30")
```

```{r fig-prof4, echo=TRUE, results="hide", fig.cap="Likelihood profile for one of the selectivity parameters."}
plot_profile(x = prof_sel1, xlab = "Sel1")
```

# Bayesian inference

Bayesian inference can be done using the `SparseNUTS` package.

```{r run-mcmc, echo=TRUE, results="hide"}
library(SparseNUTS)

# mcmc <- sample_snuts(
#   obj = obj, metric = "auto", init = "last.par.best",
#   # lower = bnd$lower, upper = bnd$upper, # these bounds dont seem to work
#   # skip_optimization = TRUE, # Can skip for Jacobians
#   num_samples = 100, num_warmup = 75, chains = 4, cores = 4,
#   control = list(adapt_delta = 0.9), globals = sbt_globals()
# )
# save(mcmc, file = "mcmc.rda")

load("mcmc.rda")
```

```{r fig-sampler-params, echo=TRUE, results="hide", fig.height=8, fig.cap="Sampler parameters."}
plot_sampler_params(fit = mcmc, plot = TRUE)
```

```{r fig-uncertainties, echo=TRUE, results="hide", fig.cap="Comparison of Bayesian and frequentist uncertainty estimates."}
# decamod::pairs_rtmb(fit = mcmc, order = "slow", pars = 1:5)
# decamod::pairs_rtmb(fit = mcmc, order = "mismatch", pars = 1:5)
# decamod::pairs_rtmb(fit = mcmc, order = "fast", pars = 1:5)
plot_uncertainties(fit = mcmc, log = TRUE, plot = TRUE)
```

# References
